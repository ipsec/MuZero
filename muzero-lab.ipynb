{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lint as: python3\n",
    "\"\"\"Pseudocode description of the MuZero algorithm.\"\"\"\n",
    "# pylint: disable=unused-argument\n",
    "# pylint: disable=missing-docstring\n",
    "# pylint: disable=g-explicit-length-test\n",
    "from typing import Any\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# MuZero training is split into two independent parts: Network training and\n",
    "# self-play data generation.\n",
    "# These two parts only communicate by transferring the latest network checkpoint\n",
    "# from the training to the self-play, and the finished games from the self-play\n",
    "# to the training.\n",
    "from config import MuZeroConfig\n",
    "from games.game import ReplayBuffer, Game, make_atari_config\n",
    "from mcts import Node, expand_node, backpropagate, add_exploration_noise, run_mcts, select_action\n",
    "from models.network import Network\n",
    "from storage import SharedStorage\n",
    "from utils import MinMaxStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def run_selfplay(config: MuZeroConfig, storage: SharedStorage, replay_buffer: ReplayBuffer):\n",
    "    #while True:\n",
    "    for _ in range(config.num_episodes):\n",
    "        network = storage.latest_network()\n",
    "        game = play_game(config, network)\n",
    "        replay_buffer.save_game(game)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def play_game(config: MuZeroConfig, network: Network) -> Game:\n",
    "    game = Game(config.action_space_size, config.discount)\n",
    "\n",
    "    while not game.terminal() and len(game.history) < config.max_moves:\n",
    "        min_max_stats = MinMaxStats(config.known_bounds)\n",
    "\n",
    "        # At the root of the search tree we use the representation function to\n",
    "        # obtain a hidden state given the current observation.\n",
    "        root = Node(0)\n",
    "        current_observation = game.make_image(-1)\n",
    "        network_output = network.initial_inference(current_observation)\n",
    "        expand_node(root, game.to_play(), game.legal_actions(), network_output)\n",
    "        backpropagate([root], network_output.value, game.to_play(), config.discount,\n",
    "                      min_max_stats)\n",
    "        add_exploration_noise(config, root)\n",
    "\n",
    "        # We then run a Monte Carlo Tree Search using only action sequences and the\n",
    "        # model learned by the network.\n",
    "        run_mcts(config, root, game.action_history(), network, min_max_stats)\n",
    "        action = select_action(config, len(game.history), root, network)\n",
    "        game.apply(action)\n",
    "        game.store_search_statistics(root)\n",
    "    return game"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def train_network(config: MuZeroConfig, storage: SharedStorage,\n",
    "                  replay_buffer: ReplayBuffer):\n",
    "    network = Network(config)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    for i in range(config.training_steps):\n",
    "        if i % config.checkpoint_interval == 0:\n",
    "            storage.save_network(i, network)\n",
    "        batch = replay_buffer.sample_batch(config.num_unroll_steps, config.td_steps)\n",
    "        update_weights(optimizer, network, batch, config.weight_decay)\n",
    "    storage.save_network(config.training_steps, network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def scale_gradient(tensor: Any, scale):\n",
    "    \"\"\"Scales the gradient for the backward pass.\"\"\"\n",
    "    return tensor * scale + tf.stop_gradient(tensor) * (1 - scale)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def update_weights(optimizer: tf.keras.optimizers.Optimizer, network: Network, batch, weight_decay: float):\n",
    "    loss = 0\n",
    "    for image, actions, targets in batch:\n",
    "        # Initial step, from the real observation.\n",
    "        network_output = network.initial_inference(image)\n",
    "        hidden_state = network_output.hidden_state\n",
    "        predictions = [(1.0, network_output)]\n",
    "\n",
    "        # Recurrent steps, from action and previous hidden state.\n",
    "        for action in actions:\n",
    "            network_output = network.recurrent_inference(hidden_state, action)\n",
    "            hidden_state = network_output.hidden_state\n",
    "            predictions.append((1.0 / len(actions), network_output))\n",
    "\n",
    "            hidden_state = scale_gradient(hidden_state, 0.5)\n",
    "\n",
    "        for k, (prediction, target) in enumerate(zip(predictions, targets)):\n",
    "            gradient_scale, network_output = prediction\n",
    "            target_value, target_reward, target_policy = target\n",
    "\n",
    "            logits = tf.stack(list(network_output.policy_logits.values()))\n",
    "            labels = tf.convert_to_tensor(target_policy)\n",
    "\n",
    "            l = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "            l += scalar_loss(network_output.value, target_value)\n",
    "            if k > 0:\n",
    "                l += scalar_loss(network_output.reward, tf.constant(target_reward, shape=(1, 1)))\n",
    "\n",
    "            loss += scale_gradient(l, gradient_scale)\n",
    "    loss /= len(batch)\n",
    "\n",
    "    for weights in network.get_weights():\n",
    "        loss += weight_decay * tf.nn.l2_loss(weights)\n",
    "\n",
    "    optimizer.minimize(loss, var_list=network.get_variables())\n",
    "    network.increment_training_steps()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def scalar_loss(prediction: tf.Tensor, target: tf.Tensor) -> float:\n",
    "    # MSE in board games, cross entropy between categorical values in Atari.\n",
    "\n",
    "    if isinstance(prediction, float):\n",
    "        prediction = tf.constant(prediction, shape=(1, 1))\n",
    "\n",
    "    if isinstance(target, float):\n",
    "        target = tf.constant(target, shape=(1, 1))\n",
    "\n",
    "    return CategoricalCrossentropy()(target, prediction).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def launch_job(f, *args):\n",
    "    f(*args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "config = make_atari_config()\n",
    "storage = SharedStorage(config)\n",
    "replay_buffer = ReplayBuffer(config)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "for _ in range(config.num_actors):\n",
    "    launch_job(run_selfplay, config, storage, replay_buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "train_network(config, storage, replay_buffer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}